======================= Training Configuration =======================
CSV Path: /home/jupyter/preprocessed_WebVid_10M_videos_0208_test_1k.csv
Video Directory: /home/jupyter/preprocessed_WebVid_10M_train_videos_0130
Output Directory: /home/jupyter/video_lora_training_checkpoints_0213
WandB Project: video_teacher_lora_training_0213
Train Batch Size: 1
Learning Rate: 1e-5
Number of Epochs: 16
Gradient Accumulation Steps: 128
Evaluate Every (epochs): 8192
Mixed Precision: bf16
Number of Workers: 4
Save Checkpoint Every (epochs): 2
VideoCrafter CKPT: scripts/evaluation/model.ckpt
VideoCrafter Config: configs/inference_t2v_512_v2.0.yaml
Video FPS: 12.5
Target Frames: 40
Random Seed: 42
VIDEO_LOSS_WEIGHT: 4.0

======================= Additional Arguments ==========================
Height: 320
Width: 512
DDIM Eta: 0.0

======================= Evaluation Configuration ======================
Inference Batch Size: 2
Inference Save Path: /home/jupyter/video_lora_inference_0213
Guidance Scale: 12.0
Number of Inference Steps: 25
Target Folder (GT): /home/jupyter/preprocessed_WebVid_10M_gt_test_videos_1k_random_crop_0210
========================================================================
git root error: Cmd('git') failed due to: exit code(128)
  cmdline: git rev-parse --show-toplevel
  stderr: 'fatal: detected dubious ownership in repository at '/home/jupyter/MMG_01'
To add an exception for this directory, call:

	git config --global --add safe.directory /home/jupyter/MMG_01'
wandb: Currently logged in as: rtrt505 to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.6
wandb: Run data is saved locally in /home/jupyter/MMG_01/wandb/run-20250213_032450-8ti1bb5t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run video_lora_training
wandb: ‚≠êÔ∏è View project at https://wandb.ai/rtrt505/video_teacher_lora_training_0213
wandb: üöÄ View run at https://wandb.ai/rtrt505/video_teacher_lora_training_0213/runs/8ti1bb5t
AE working on z of shape (1, 4, 64, 64) = 16384 dimensions.
AE working on z of shape (1, 4, 64, 64) = 16384 dimensions.
AE working on z of shape (1, 4, 64, 64) = 16384 dimensions.
WARNING:py.warnings:/opt/conda/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)

WARNING:py.warnings:/opt/conda/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)

WARNING:py.warnings:/opt/conda/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)

INFO:root:Loaded ViT-H-14 model config.
INFO:root:Loaded ViT-H-14 model config.
INFO:root:Loaded ViT-H-14 model config.
AE working on z of shape (1, 4, 64, 64) = 16384 dimensions.
WARNING:py.warnings:/opt/conda/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)

INFO:root:Loaded ViT-H-14 model config.
WARNING:py.warnings:/home/jupyter/MMG_01/video_lora_training/train.py:157: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(args.videocrafter_ckpt)['state_dict']

WARNING:py.warnings:/home/jupyter/MMG_01/video_lora_training/train.py:157: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(args.videocrafter_ckpt)['state_dict']

WARNING:py.warnings:/home/jupyter/MMG_01/video_lora_training/train.py:157: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(args.videocrafter_ckpt)['state_dict']

WARNING:py.warnings:/home/jupyter/MMG_01/video_lora_training/train.py:157: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(args.videocrafter_ckpt)['state_dict']

video_lora_training/train.sh: line 138: 1824666 Killed                  accelerate launch video_lora_training/train.py --csv_path "$VIDEO_CSV_PATH" --video_dir "$VIDEO_DIR" --output_dir "$OUTPUT_DIR" --wandb_project "$WANDB_PROJECT" --train_batch_size "$TRAIN_BATCH_SIZE" --lr "$LR" --num_epochs "$NUM_EPOCHS" --gradient_accumulation_steps "$GRAD_ACC_STEPS" --eval_every "$EVAL_EVERY" --mixed_precision "$MIXED_PRECISION" --num_workers "$NUM_WORKERS" --save_checkpoint "$SAVE_CHECKPOINT" --videocrafter_ckpt "$VIDEOCRAFTER_CKPT" --videocrafter_config "$VIDEOCRAFTER_CONFIG" --video_fps "$VIDEO_FPS" --target_frames "$TARGET_FRAMES" --inference_batch_size "$INFERENCE_BATCH_SIZE" --inference_save_path "$INFERENCE_SAVE_PATH" --guidance_scale "$GUIDANCE_SCALE" --num_inference_steps "$NUM_INFERENCE_STEPS" --target_folder "$TARGET_FOLDER" --height "$HEIGHT" --width "$WIDTH" --ddim_eta "$DDIM_ETA" --seed "$SEED" --vgg_csv_path "$VGG_CSV_PATH" --vgg_inference_save_path "$VGG_INFERENCE_SAVE_PATH" --vgg_target_folder "$VGG_TARGET_FOLDER" --video_loss_weight "$VIDEO_LOSS_WEIGHT"
Training failed. Please check the logs for more details.
Ï†ÑÏ≤¥ ÌååÎùºÎØ∏ÌÑ∞ Í∞úÏàò: 1519616580
ÌïôÏäµ Í∞ÄÎä•Ìïú ÌååÎùºÎØ∏ÌÑ∞ Í∞úÏàò: 106332160
Ï†ÑÏ≤¥ ÌååÎùºÎØ∏ÌÑ∞ Í∞úÏàò: 1519616580
ÌïôÏäµ Í∞ÄÎä•Ìïú ÌååÎùºÎØ∏ÌÑ∞ Í∞úÏàò: 106332160
Ï†ÑÏ≤¥ ÌååÎùºÎØ∏ÌÑ∞ Í∞úÏàò: 1519616580
ÌïôÏäµ Í∞ÄÎä•Ìïú ÌååÎùºÎØ∏ÌÑ∞ Í∞úÏàò: 106332160
Ï†ÑÏ≤¥ ÌååÎùºÎØ∏ÌÑ∞ Í∞úÏàò: 1519616580
ÌïôÏäµ Í∞ÄÎä•Ìïú ÌååÎùºÎØ∏ÌÑ∞ Í∞úÏàò: 106332160
[rank3]: Traceback (most recent call last):
[rank3]:   File "/home/jupyter/MMG_01/video_lora_training/train.py", line 434, in <module>
[rank3]:     main(args)
[rank3]:   File "/home/jupyter/MMG_01/video_lora_training/train.py", line 187, in main
[rank3]:     video_unet, optimizer, train_loader = accelerator.prepare(
[rank3]:   File "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py", line 1339, in prepare
[rank3]:     result = tuple(
[rank3]:   File "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py", line 1340, in <genexpr>
[rank3]:     self._prepare_one(obj, first_pass=True, device_placement=d) for obj, d in zip(args, device_placement)
[rank3]:   File "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py", line 1215, in _prepare_one
[rank3]:     return self.prepare_model(obj, device_placement=device_placement)
[rank3]:   File "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py", line 1469, in prepare_model
[rank3]:     model = torch.nn.parallel.DistributedDataParallel(
[rank3]:   File "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 825, in __init__
[rank3]:     _verify_param_shape_across_processes(self.process_group, parameters)
[rank3]:   File "/opt/conda/lib/python3.10/site-packages/torch/distributed/utils.py", line 288, in _verify_param_shape_across_processes
[rank3]:     return dist._verify_params_across_processes(process_group, tensors, logger)
[rank3]: torch.distributed.DistBackendError: [3] is setting up NCCL communicator and retrieving ncclUniqueId from [0] via c10d key-value store by key '0', but store->get('0') got error: failed to recv, got 0 bytes
[rank3]: Exception raised from recvBytes at ../torch/csrc/distributed/c10d/Utils.hpp:670 (most recent call first):
[rank3]: frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7fdf2727f446 in /opt/conda/lib/python3.10/site-packages/torch/lib/libc10.so)
[rank3]: frame #1: <unknown function> + 0x5fed998 (0x7fdf62951998 in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank3]: frame #2: c10d::TCPStore::doWait(c10::ArrayRef<std::string>, std::chrono::duration<long, std::ratio<1l, 1000l> >) + 0x35b (0x7fdf6294e64b in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank3]: frame #3: c10d::TCPStore::doGet(std::string const&) + 0x2a (0x7fdf6294e9ca in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank3]: frame #4: c10d::TCPStore::get(std::string const&) + 0x7a (0x7fdf6294f83a in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank3]: frame #5: c10d::PrefixStore::get(std::string const&) + 0x31 (0x7fdf628ffbc1 in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank3]: frame #6: c10d::PrefixStore::get(std::string const&) + 0x31 (0x7fdf628ffbc1 in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank3]: frame #7: c10d::PrefixStore::get(std::string const&) + 0x31 (0x7fdf628ffbc1 in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank3]: frame #8: c10d::PrefixStore::get(std::string const&) + 0x31 (0x7fdf628ffbc1 in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank3]: frame #9: c10d::ProcessGroupNCCL::broadcastUniqueNCCLID(ncclUniqueId*, bool, std::string const&, int) + 0xaf (0x7fdf285c5ebf in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
[rank3]: frame #10: c10d::ProcessGroupNCCL::getNCCLComm(std::string const&, c10::Device&, c10d::OpType, int, bool) + 0xfbd (0x7fdf285d1e5d in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
[rank3]: frame #11: c10d::ProcessGroupNCCL::allgather(std::vector<std::vector<at::Tensor, std::allocator<at::Tensor> >, std::allocator<std::vector<at::Tensor, std::allocator<at::Tensor> > > >&, std::vector<at::Tensor, std::allocator<at::Tensor> >&, c10d::AllgatherOptions const&) + 0x992 (0x7fdf285e3102 in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
[rank3]: frame #12: <unknown function> + 0x5f902ed (0x7fdf628f42ed in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank3]: frame #13: <unknown function> + 0x5f994c7 (0x7fdf628fd4c7 in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank3]: frame #14: <unknown function> + 0x55b224b (0x7fdf61f1624b in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank3]: frame #15: <unknown function> + 0x55afad9 (0x7fdf61f13ad9 in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank3]: frame #16: <unknown function> + 0x1a8c3f8 (0x7fdf5e3f03f8 in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank3]: frame #17: <unknown function> + 0x5fa16a3 (0x7fdf629056a3 in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank3]: frame #18: <unknown function> + 0x5faca2f (0x7fdf62910a2f in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank3]: frame #19: c10d::verify_params_across_processes(c10::intrusive_ptr<c10d::ProcessGroup, c10::detail::intrusive_target_default_null_type<c10d::ProcessGroup> > const&, std::vector<at::Tensor, std::allocator<at::Tensor> > const&, std::optional<std::weak_ptr<c10d::Logger> > const&) + 0x26d (0x7fdf6297a68d in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank3]: frame #20: <unknown function> + 0xd98cb1 (0x7fdf72361cb1 in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
[rank3]: frame #21: <unknown function> + 0x4cb474 (0x7fdf71a94474 in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
[rank3]: frame #22: <unknown function> + 0x13bc46 (0x55c1fe8b2c46 in /opt/conda/bin/python3.10)
[rank3]: frame #23: _PyObject_MakeTpCall + 0x2d3 (0x55c1fe8abf73 in /opt/conda/bin/python3.10)
[rank3]: frame #24: _PyEval_EvalFrameDefault + 0x51f6 (0x55c1fe8a8176 in /opt/conda/bin/python3.10)
[rank3]: frame #25: _PyFunction_Vectorcall + 0x6c (0x55c1fe8b30cc in /opt/conda/bin/python3.10)
[rank3]: frame #26: _PyEval_EvalFrameDefault + 0x30c (0x55c1fe8a328c in /opt/conda/bin/python3.10)
[rank3]: frame #27: _PyFunction_Vectorcall + 0x6c (0x55c1fe8b30cc in /opt/conda/bin/python3.10)
[rank3]: frame #28: _PyObject_FastCallDictTstate + 0x187 (0x55c1fe8ab4b7 in /opt/conda/bin/python3.10)
[rank3]: frame #29: <unknown function> + 0x145009 (0x55c1fe8bc009 in /opt/conda/bin/python3.10)
[rank3]: frame #30: <unknown function> + 0x13527b (0x55c1fe8ac27b in /opt/conda/bin/python3.10)
[rank3]: frame #31: PyObject_Call + 0x20f (0x55c1fe8befcf in /opt/conda/bin/python3.10)
[rank3]: frame #32: _PyEval_EvalFrameDefault + 0x2d62 (0x55c1fe8a5ce2 in /opt/conda/bin/python3.10)
[rank3]: frame #33: <unknown function> + 0x1474e2 (0x55c1fe8be4e2 in /opt/conda/bin/python3.10)
[rank3]: frame #34: _PyEval_EvalFrameDefault + 0x133e (0x55c1fe8a42be in /opt/conda/bin/python3.10)
[rank3]: frame #35: <unknown function> + 0x1474e2 (0x55c1fe8be4e2 in /opt/conda/bin/python3.10)
[rank3]: frame #36: _PyEval_EvalFrameDefault + 0x133e (0x55c1fe8a42be in /opt/conda/bin/python3.10)
[rank3]: frame #37: <unknown function> + 0x14e8e7 (0x55c1fe8c58e7 in /opt/conda/bin/python3.10)
[rank3]: frame #38: PySequence_Tuple + 0x1fc (0x55c1fe892f8c in /opt/conda/bin/python3.10)
[rank3]: frame #39: _PyEval_EvalFrameDefault + 0x30c (0x55c1fe8a328c in /opt/conda/bin/python3.10)
[rank3]: frame #40: _PyFunction_Vectorcall + 0x6c (0x55c1fe8b30cc in /opt/conda/bin/python3.10)
[rank3]: frame #41: _PyEval_EvalFrameDefault + 0x700 (0x55c1fe8a3680 in /opt/conda/bin/python3.10)
[rank3]: frame #42: _PyFunction_Vectorcall + 0x6c (0x55c1fe8b30cc in /opt/conda/bin/python3.10)
[rank3]: frame #43: _PyEval_EvalFrameDefault + 0x30c (0x55c1fe8a328c in /opt/conda/bin/python3.10)
[rank3]: frame #44: <unknown function> + 0x1cc80c (0x55c1fe94380c in /opt/conda/bin/python3.10)
[rank3]: frame #45: PyEval_EvalCode + 0x87 (0x55c1fe943757 in /opt/conda/bin/python3.10)
[rank3]: frame #46: <unknown function> + 0x1fcb1a (0x55c1fe973b1a in /opt/conda/bin/python3.10)
[rank3]: frame #47: <unknown function> + 0x1f7fa3 (0x55c1fe96efa3 in /opt/conda/bin/python3.10)
[rank3]: frame #48: <unknown function> + 0x972c2 (0x55c1fe80e2c2 in /opt/conda/bin/python3.10)
[rank3]: frame #49: _PyRun_SimpleFileObject + 0x1bd (0x55c1fe9697dd in /opt/conda/bin/python3.10)
[rank3]: frame #50: _PyRun_AnyFileObject + 0x44 (0x55c1fe969374 in /opt/conda/bin/python3.10)
[rank3]: frame #51: Py_RunMain + 0x31b (0x55c1fe9666db in /opt/conda/bin/python3.10)
[rank3]: frame #52: Py_BytesMain + 0x37 (0x55c1fe936e97 in /opt/conda/bin/python3.10)
[rank3]: frame #53: __libc_start_main + 0xea (0x7fdf7370bd7a in /lib/x86_64-linux-gnu/libc.so.6)
[rank3]: frame #54: <unknown function> + 0x1bfdae (0x55c1fe936dae in /opt/conda/bin/python3.10)
[rank3]: . This may indicate a possible application crash on rank 0 or a network set up issue.
[rank2]: Traceback (most recent call last):
[rank2]:   File "/home/jupyter/MMG_01/video_lora_training/train.py", line 434, in <module>
[rank2]:     main(args)
[rank2]:   File "/home/jupyter/MMG_01/video_lora_training/train.py", line 187, in main
[rank2]:     video_unet, optimizer, train_loader = accelerator.prepare(
[rank2]:   File "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py", line 1339, in prepare
[rank2]:     result = tuple(
[rank2]:   File "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py", line 1340, in <genexpr>
[rank2]:     self._prepare_one(obj, first_pass=True, device_placement=d) for obj, d in zip(args, device_placement)
[rank2]:   File "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py", line 1215, in _prepare_one
[rank2]:     return self.prepare_model(obj, device_placement=device_placement)
[rank2]:   File "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py", line 1469, in prepare_model
[rank2]:     model = torch.nn.parallel.DistributedDataParallel(
[rank2]:   File "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 825, in __init__
[rank2]:     _verify_param_shape_across_processes(self.process_group, parameters)
[rank2]:   File "/opt/conda/lib/python3.10/site-packages/torch/distributed/utils.py", line 288, in _verify_param_shape_across_processes
[rank2]:     return dist._verify_params_across_processes(process_group, tensors, logger)
[rank2]: torch.distributed.DistBackendError: [2] is setting up NCCL communicator and retrieving ncclUniqueId from [0] via c10d key-value store by key '0', but store->get('0') got error: failed to recv, got 0 bytes
[rank2]: Exception raised from recvBytes at ../torch/csrc/distributed/c10d/Utils.hpp:670 (most recent call first):
[rank2]: frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7fbd7ba6c446 in /opt/conda/lib/python3.10/site-packages/torch/lib/libc10.so)
[rank2]: frame #1: <unknown function> + 0x5fed998 (0x7fbdb713e998 in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank2]: frame #2: c10d::TCPStore::doWait(c10::ArrayRef<std::string>, std::chrono::duration<long, std::ratio<1l, 1000l> >) + 0x35b (0x7fbdb713b64b in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank2]: frame #3: c10d::TCPStore::doGet(std::string const&) + 0x2a (0x7fbdb713b9ca in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank2]: frame #4: c10d::TCPStore::get(std::string const&) + 0x7a (0x7fbdb713c83a in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank2]: frame #5: c10d::PrefixStore::get(std::string const&) + 0x31 (0x7fbdb70ecbc1 in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank2]: frame #6: c10d::PrefixStore::get(std::string const&) + 0x31 (0x7fbdb70ecbc1 in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank2]: frame #7: c10d::PrefixStore::get(std::string const&) + 0x31 (0x7fbdb70ecbc1 in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank2]: frame #8: c10d::PrefixStore::get(std::string const&) + 0x31 (0x7fbdb70ecbc1 in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank2]: frame #9: c10d::ProcessGroupNCCL::broadcastUniqueNCCLID(ncclUniqueId*, bool, std::string const&, int) + 0xaf (0x7fbd7cdb2ebf in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
[rank2]: frame #10: c10d::ProcessGroupNCCL::getNCCLComm(std::string const&, c10::Device&, c10d::OpType, int, bool) + 0xfbd (0x7fbd7cdbee5d in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
[rank2]: frame #11: c10d::ProcessGroupNCCL::allgather(std::vector<std::vector<at::Tensor, std::allocator<at::Tensor> >, std::allocator<std::vector<at::Tensor, std::allocator<at::Tensor> > > >&, std::vector<at::Tensor, std::allocator<at::Tensor> >&, c10d::AllgatherOptions const&) + 0x992 (0x7fbd7cdd0102 in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
[rank2]: frame #12: <unknown function> + 0x5f902ed (0x7fbdb70e12ed in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank2]: frame #13: <unknown function> + 0x5f994c7 (0x7fbdb70ea4c7 in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank2]: frame #14: <unknown function> + 0x55b224b (0x7fbdb670324b in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank2]: frame #15: <unknown function> + 0x55afad9 (0x7fbdb6700ad9 in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank2]: frame #16: <unknown function> + 0x1a8c3f8 (0x7fbdb2bdd3f8 in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank2]: frame #17: <unknown function> + 0x5fa16a3 (0x7fbdb70f26a3 in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank2]: frame #18: <unknown function> + 0x5faca2f (0x7fbdb70fda2f in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank2]: frame #19: c10d::verify_params_across_processes(c10::intrusive_ptr<c10d::ProcessGroup, c10::detail::intrusive_target_default_null_type<c10d::ProcessGroup> > const&, std::vector<at::Tensor, std::allocator<at::Tensor> > const&, std::optional<std::weak_ptr<c10d::Logger> > const&) + 0x26d (0x7fbdb716768d in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank2]: frame #20: <unknown function> + 0xd98cb1 (0x7fbdc6b4ecb1 in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
[rank2]: frame #21: <unknown function> + 0x4cb474 (0x7fbdc6281474 in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
[rank2]: frame #22: <unknown function> + 0x13bc46 (0x55e15eeefc46 in /opt/conda/bin/python3.10)
[rank2]: frame #23: _PyObject_MakeTpCall + 0x2d3 (0x55e15eee8f73 in /opt/conda/bin/python3.10)
[rank2]: frame #24: _PyEval_EvalFrameDefault + 0x51f6 (0x55e15eee5176 in /opt/conda/bin/python3.10)
[rank2]: frame #25: _PyFunction_Vectorcall + 0x6c (0x55e15eef00cc in /opt/conda/bin/python3.10)
[rank2]: frame #26: _PyEval_EvalFrameDefault + 0x30c (0x55e15eee028c in /opt/conda/bin/python3.10)
[rank2]: frame #27: _PyFunction_Vectorcall + 0x6c (0x55e15eef00cc in /opt/conda/bin/python3.10)
[rank2]: frame #28: _PyObject_FastCallDictTstate + 0x187 (0x55e15eee84b7 in /opt/conda/bin/python3.10)
[rank2]: frame #29: <unknown function> + 0x145009 (0x55e15eef9009 in /opt/conda/bin/python3.10)
[rank2]: frame #30: <unknown function> + 0x13527b (0x55e15eee927b in /opt/conda/bin/python3.10)
[rank2]: frame #31: PyObject_Call + 0x20f (0x55e15eefbfcf in /opt/conda/bin/python3.10)
[rank2]: frame #32: _PyEval_EvalFrameDefault + 0x2d62 (0x55e15eee2ce2 in /opt/conda/bin/python3.10)
[rank2]: frame #33: <unknown function> + 0x1474e2 (0x55e15eefb4e2 in /opt/conda/bin/python3.10)
[rank2]: frame #34: _PyEval_EvalFrameDefault + 0x133e (0x55e15eee12be in /opt/conda/bin/python3.10)
[rank2]: frame #35: <unknown function> + 0x1474e2 (0x55e15eefb4e2 in /opt/conda/bin/python3.10)
[rank2]: frame #36: _PyEval_EvalFrameDefault + 0x133e (0x55e15eee12be in /opt/conda/bin/python3.10)
[rank2]: frame #37: <unknown function> + 0x14e8e7 (0x55e15ef028e7 in /opt/conda/bin/python3.10)
[rank2]: frame #38: PySequence_Tuple + 0x1fc (0x55e15eecff8c in /opt/conda/bin/python3.10)
[rank2]: frame #39: _PyEval_EvalFrameDefault + 0x30c (0x55e15eee028c in /opt/conda/bin/python3.10)
[rank2]: frame #40: _PyFunction_Vectorcall + 0x6c (0x55e15eef00cc in /opt/conda/bin/python3.10)
[rank2]: frame #41: _PyEval_EvalFrameDefault + 0x700 (0x55e15eee0680 in /opt/conda/bin/python3.10)
[rank2]: frame #42: _PyFunction_Vectorcall + 0x6c (0x55e15eef00cc in /opt/conda/bin/python3.10)
[rank2]: frame #43: _PyEval_EvalFrameDefault + 0x30c (0x55e15eee028c in /opt/conda/bin/python3.10)
[rank2]: frame #44: <unknown function> + 0x1cc80c (0x55e15ef8080c in /opt/conda/bin/python3.10)
[rank2]: frame #45: PyEval_EvalCode + 0x87 (0x55e15ef80757 in /opt/conda/bin/python3.10)
[rank2]: frame #46: <unknown function> + 0x1fcb1a (0x55e15efb0b1a in /opt/conda/bin/python3.10)
[rank2]: frame #47: <unknown function> + 0x1f7fa3 (0x55e15efabfa3 in /opt/conda/bin/python3.10)
[rank2]: frame #48: <unknown function> + 0x972c2 (0x55e15ee4b2c2 in /opt/conda/bin/python3.10)
[rank2]: frame #49: _PyRun_SimpleFileObject + 0x1bd (0x55e15efa67dd in /opt/conda/bin/python3.10)
[rank2]: frame #50: _PyRun_AnyFileObject + 0x44 (0x55e15efa6374 in /opt/conda/bin/python3.10)
[rank2]: frame #51: Py_RunMain + 0x31b (0x55e15efa36db in /opt/conda/bin/python3.10)
[rank2]: frame #52: Py_BytesMain + 0x37 (0x55e15ef73e97 in /opt/conda/bin/python3.10)
[rank2]: frame #53: __libc_start_main + 0xea (0x7fbdc7ef8d7a in /lib/x86_64-linux-gnu/libc.so.6)
[rank2]: frame #54: <unknown function> + 0x1bfdae (0x55e15ef73dae in /opt/conda/bin/python3.10)
[rank2]: . This may indicate a possible application crash on rank 0 or a network set up issue.
[rank1]: Traceback (most recent call last):
[rank1]:   File "/home/jupyter/MMG_01/video_lora_training/train.py", line 434, in <module>
[rank1]:     main(args)
[rank1]:   File "/home/jupyter/MMG_01/video_lora_training/train.py", line 187, in main
[rank1]:     video_unet, optimizer, train_loader = accelerator.prepare(
[rank1]:   File "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py", line 1339, in prepare
[rank1]:     result = tuple(
[rank1]:   File "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py", line 1340, in <genexpr>
[rank1]:     self._prepare_one(obj, first_pass=True, device_placement=d) for obj, d in zip(args, device_placement)
[rank1]:   File "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py", line 1215, in _prepare_one
[rank1]:     return self.prepare_model(obj, device_placement=device_placement)
[rank1]:   File "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py", line 1469, in prepare_model
[rank1]:     model = torch.nn.parallel.DistributedDataParallel(
[rank1]:   File "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 825, in __init__
[rank1]:     _verify_param_shape_across_processes(self.process_group, parameters)
[rank1]:   File "/opt/conda/lib/python3.10/site-packages/torch/distributed/utils.py", line 288, in _verify_param_shape_across_processes
[rank1]:     return dist._verify_params_across_processes(process_group, tensors, logger)
[rank1]: torch.distributed.DistBackendError: [1] is setting up NCCL communicator and retrieving ncclUniqueId from [0] via c10d key-value store by key '0', but store->get('0') got error: failed to recv, got 0 bytes
[rank1]: Exception raised from recvBytes at ../torch/csrc/distributed/c10d/Utils.hpp:670 (most recent call first):
[rank1]: frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7fbdb8433446 in /opt/conda/lib/python3.10/site-packages/torch/lib/libc10.so)
[rank1]: frame #1: <unknown function> + 0x5fed998 (0x7fbdf3b05998 in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank1]: frame #2: c10d::TCPStore::doWait(c10::ArrayRef<std::string>, std::chrono::duration<long, std::ratio<1l, 1000l> >) + 0x35b (0x7fbdf3b0264b in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank1]: frame #3: c10d::TCPStore::doGet(std::string const&) + 0x2a (0x7fbdf3b029ca in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank1]: frame #4: c10d::TCPStore::get(std::string const&) + 0x7a (0x7fbdf3b0383a in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank1]: frame #5: c10d::PrefixStore::get(std::string const&) + 0x31 (0x7fbdf3ab3bc1 in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank1]: frame #6: c10d::PrefixStore::get(std::string const&) + 0x31 (0x7fbdf3ab3bc1 in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank1]: frame #7: c10d::PrefixStore::get(std::string const&) + 0x31 (0x7fbdf3ab3bc1 in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank1]: frame #8: c10d::PrefixStore::get(std::string const&) + 0x31 (0x7fbdf3ab3bc1 in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank1]: frame #9: c10d::ProcessGroupNCCL::broadcastUniqueNCCLID(ncclUniqueId*, bool, std::string const&, int) + 0xaf (0x7fbdb9779ebf in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
[rank1]: frame #10: c10d::ProcessGroupNCCL::getNCCLComm(std::string const&, c10::Device&, c10d::OpType, int, bool) + 0xfbd (0x7fbdb9785e5d in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
[rank1]: frame #11: c10d::ProcessGroupNCCL::allgather(std::vector<std::vector<at::Tensor, std::allocator<at::Tensor> >, std::allocator<std::vector<at::Tensor, std::allocator<at::Tensor> > > >&, std::vector<at::Tensor, std::allocator<at::Tensor> >&, c10d::AllgatherOptions const&) + 0x992 (0x7fbdb9797102 in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
[rank1]: frame #12: <unknown function> + 0x5f902ed (0x7fbdf3aa82ed in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank1]: frame #13: <unknown function> + 0x5f994c7 (0x7fbdf3ab14c7 in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank1]: frame #14: <unknown function> + 0x55b224b (0x7fbdf30ca24b in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank1]: frame #15: <unknown function> + 0x55afad9 (0x7fbdf30c7ad9 in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank1]: frame #16: <unknown function> + 0x1a8c3f8 (0x7fbdef5a43f8 in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank1]: frame #17: <unknown function> + 0x5fa16a3 (0x7fbdf3ab96a3 in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank1]: frame #18: <unknown function> + 0x5faca2f (0x7fbdf3ac4a2f in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank1]: frame #19: c10d::verify_params_across_processes(c10::intrusive_ptr<c10d::ProcessGroup, c10::detail::intrusive_target_default_null_type<c10d::ProcessGroup> > const&, std::vector<at::Tensor, std::allocator<at::Tensor> > const&, std::optional<std::weak_ptr<c10d::Logger> > const&) + 0x26d (0x7fbdf3b2e68d in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank1]: frame #20: <unknown function> + 0xd98cb1 (0x7fbe03515cb1 in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
[rank1]: frame #21: <unknown function> + 0x4cb474 (0x7fbe02c48474 in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
[rank1]: frame #22: <unknown function> + 0x13bc46 (0x564bcc62ec46 in /opt/conda/bin/python3.10)
[rank1]: frame #23: _PyObject_MakeTpCall + 0x2d3 (0x564bcc627f73 in /opt/conda/bin/python3.10)
[rank1]: frame #24: _PyEval_EvalFrameDefault + 0x51f6 (0x564bcc624176 in /opt/conda/bin/python3.10)
[rank1]: frame #25: _PyFunction_Vectorcall + 0x6c (0x564bcc62f0cc in /opt/conda/bin/python3.10)
[rank1]: frame #26: _PyEval_EvalFrameDefault + 0x30c (0x564bcc61f28c in /opt/conda/bin/python3.10)
[rank1]: frame #27: _PyFunction_Vectorcall + 0x6c (0x564bcc62f0cc in /opt/conda/bin/python3.10)
[rank1]: frame #28: _PyObject_FastCallDictTstate + 0x187 (0x564bcc6274b7 in /opt/conda/bin/python3.10)
[rank1]: frame #29: <unknown function> + 0x145009 (0x564bcc638009 in /opt/conda/bin/python3.10)
[rank1]: frame #30: <unknown function> + 0x13527b (0x564bcc62827b in /opt/conda/bin/python3.10)
[rank1]: frame #31: PyObject_Call + 0x20f (0x564bcc63afcf in /opt/conda/bin/python3.10)
[rank1]: frame #32: _PyEval_EvalFrameDefault + 0x2d62 (0x564bcc621ce2 in /opt/conda/bin/python3.10)
[rank1]: frame #33: <unknown function> + 0x1474e2 (0x564bcc63a4e2 in /opt/conda/bin/python3.10)
[rank1]: frame #34: _PyEval_EvalFrameDefault + 0x133e (0x564bcc6202be in /opt/conda/bin/python3.10)
[rank1]: frame #35: <unknown function> + 0x1474e2 (0x564bcc63a4e2 in /opt/conda/bin/python3.10)
[rank1]: frame #36: _PyEval_EvalFrameDefault + 0x133e (0x564bcc6202be in /opt/conda/bin/python3.10)
[rank1]: frame #37: <unknown function> + 0x14e8e7 (0x564bcc6418e7 in /opt/conda/bin/python3.10)
[rank1]: frame #38: PySequence_Tuple + 0x1fc (0x564bcc60ef8c in /opt/conda/bin/python3.10)
[rank1]: frame #39: _PyEval_EvalFrameDefault + 0x30c (0x564bcc61f28c in /opt/conda/bin/python3.10)
[rank1]: frame #40: _PyFunction_Vectorcall + 0x6c (0x564bcc62f0cc in /opt/conda/bin/python3.10)
[rank1]: frame #41: _PyEval_EvalFrameDefault + 0x700 (0x564bcc61f680 in /opt/conda/bin/python3.10)
[rank1]: frame #42: _PyFunction_Vectorcall + 0x6c (0x564bcc62f0cc in /opt/conda/bin/python3.10)
[rank1]: frame #43: _PyEval_EvalFrameDefault + 0x30c (0x564bcc61f28c in /opt/conda/bin/python3.10)
[rank1]: frame #44: <unknown function> + 0x1cc80c (0x564bcc6bf80c in /opt/conda/bin/python3.10)
[rank1]: frame #45: PyEval_EvalCode + 0x87 (0x564bcc6bf757 in /opt/conda/bin/python3.10)
[rank1]: frame #46: <unknown function> + 0x1fcb1a (0x564bcc6efb1a in /opt/conda/bin/python3.10)
[rank1]: frame #47: <unknown function> + 0x1f7fa3 (0x564bcc6eafa3 in /opt/conda/bin/python3.10)
[rank1]: frame #48: <unknown function> + 0x972c2 (0x564bcc58a2c2 in /opt/conda/bin/python3.10)
[rank1]: frame #49: _PyRun_SimpleFileObject + 0x1bd (0x564bcc6e57dd in /opt/conda/bin/python3.10)
[rank1]: frame #50: _PyRun_AnyFileObject + 0x44 (0x564bcc6e5374 in /opt/conda/bin/python3.10)
[rank1]: frame #51: Py_RunMain + 0x31b (0x564bcc6e26db in /opt/conda/bin/python3.10)
[rank1]: frame #52: Py_BytesMain + 0x37 (0x564bcc6b2e97 in /opt/conda/bin/python3.10)
[rank1]: frame #53: __libc_start_main + 0xea (0x7fbe048bfd7a in /lib/x86_64-linux-gnu/libc.so.6)
[rank1]: frame #54: <unknown function> + 0x1bfdae (0x564bcc6b2dae in /opt/conda/bin/python3.10)
[rank1]: . This may indicate a possible application crash on rank 0 or a network set up issue.
