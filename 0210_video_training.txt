======================= Training Configuration =======================
CSV Path: /home/jupyter/preprocessed_WebVid_10M_videos_0208_test_1k.csv
Video Directory: /home/jupyter/preprocessed_WebVid_10M_train_videos_0130
Output Directory: /home/jupyter/video_lora_training_checkpoints_0211
WandB Project: video_teacher_lora_training_0211
Train Batch Size: 1
Learning Rate: 1e-6
Number of Epochs: 16
Gradient Accumulation Steps: 128
Evaluate Every (epochs): 2048
Mixed Precision: bf16
Number of Workers: 4
Save Checkpoint Every (epochs): 2
VideoCrafter CKPT: scripts/evaluation/model.ckpt
VideoCrafter Config: configs/inference_t2v_512_v2.0.yaml
Video FPS: 12.5
Target Frames: 40
Random Seed: 42

======================= Additional Arguments ==========================
Height: 320
Width: 512
DDIM Eta: 0.0

======================= Evaluation Configuration ======================
Inference Batch Size: 2
Inference Save Path: /home/jupyter/video_lora_inference_0211
Guidance Scale: 12.0
Number of Inference Steps: 25
Target Folder (GT): /home/jupyter/preprocessed_WebVid_10M_gt_test_videos_1k_random_crop_0210
========================================================================
git root error: Cmd('git') failed due to: exit code(128)
  cmdline: git rev-parse --show-toplevel
  stderr: 'fatal: detected dubious ownership in repository at '/home/jupyter/MMG_01'
To add an exception for this directory, call:

	git config --global --add safe.directory /home/jupyter/MMG_01'
wandb: Currently logged in as: rtrt505 to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.6
wandb: Run data is saved locally in /home/jupyter/MMG_01/wandb/run-20250211_013611-zrta49i6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run video_lora_training
wandb: ‚≠êÔ∏è View project at https://wandb.ai/rtrt505/video_teacher_lora_training_0211
wandb: üöÄ View run at https://wandb.ai/rtrt505/video_teacher_lora_training_0211/runs/zrta49i6
AE working on z of shape (1, 4, 64, 64) = 16384 dimensions.
AE working on z of shape (1, 4, 64, 64) = 16384 dimensions.
AE working on z of shape (1, 4, 64, 64) = 16384 dimensions.
AE working on z of shape (1, 4, 64, 64) = 16384 dimensions.
WARNING:py.warnings:/opt/conda/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)

WARNING:py.warnings:/opt/conda/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)

WARNING:py.warnings:/opt/conda/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)

INFO:root:Loaded ViT-H-14 model config.
INFO:root:Loaded ViT-H-14 model config.
INFO:root:Loaded ViT-H-14 model config.
WARNING:py.warnings:/opt/conda/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)

INFO:root:Loaded ViT-H-14 model config.
WARNING:py.warnings:/home/jupyter/MMG_01/video_lora_training/train.py:156: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(args.videocrafter_ckpt)['state_dict']

WARNING:py.warnings:/home/jupyter/MMG_01/video_lora_training/train.py:156: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary AE working on z of shape (1, 4, 64, 64) = 16384 dimensions.
WARNING:py.warnings:/opt/conda/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)

INFO:root:Loaded ViT-H-14 model config.
WARNING:py.warnings:/home/jupyter/MMG_01/video_lora_training/train.py:156: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(args.videocrafter_ckpt)['state_dict']

WARNING:py.warnings:/home/jupyter/MMG_01/video_lora_training/train.py:156: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(args.videocrafter_ckpt)['state_dict']

Ï†ÑÏ≤¥ ÌååÎùºÎØ∏ÌÑ∞ Í∞úÏàò: 1466450500
ÌïôÏäµ Í∞ÄÎä•Ìïú ÌååÎùºÎØ∏ÌÑ∞ Í∞úÏàò: 53166080
[rank1]: Traceback (most recent call last):
[rank1]:   File "/home/jupyter/MMG_01/video_lora_training/train.py", line 426, in <module>
[rank1]:     main(args)
[rank1]:   File "/home/jupyter/MMG_01/video_lora_training/train.py", line 186, in main
[rank1]:     video_unet, optimizer, train_loader = accelerator.prepare(
[rank1]:   File "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py", line 1339, in prepare
[rank1]:     result = tuple(
[rank1]:   File "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py", line 1340, in <genexpr>
[rank1]:     self._prepare_one(obj, first_pass=True, device_placement=d) for obj, d in zip(args, device_placement)
[rank1]:   File "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py", line 1215, in _prepare_one
[rank1]:     return self.prepare_model(obj, device_placement=device_placement)
[rank1]:
Generating:   3%|‚ñé         | 1/37 [00:54<32:39, 54.42s/it][Avideo_lora_training/train.sh: line 132: 787923 Killed                  accelerate launch video_lora_training/train.py --csv_path "$VIDEO_CSV_PATH" --video_dir "$VIDEO_DIR" --output_dir "$OUTPUT_DIR" --wandb_project "$WANDB_PROJECT" --train_batch_size "$TRAIN_BATCH_SIZE" --lr "$LR" --num_epochs "$NUM_EPOCHS" --gradient_accumulation_steps "$GRAD_ACC_STEPS" --eval_every "$EVAL_EVERY" --mixed_precision "$MIXED_PRECISION" --num_workers "$NUM_WORKERS" --save_checkpoint "$SAVE_CHECKPOINT" --videocrafter_ckpt "$VIDEOCRAFTER_CKPT" --videocrafter_config "$VIDEOCRAFTER_CONFIG" --video_fps "$VIDEO_FPS" --target_frames "$TARGET_FRAMES" --inference_batch_size "$INFERENCE_BATCH_SIZE" --inference_save_path "$INFERENCE_SAVE_PATH" --guidance_scale "$GUIDANCE_SCALE" --num_inference_steps "$NUM_INFERENCE_STEPS" --target_folder "$TARGET_FOLDER" --height "$HEIGHT" --width "$WIDTH" --ddim_eta "$DDIM_ETA" --seed "$SEED" --vgg_csv_path "$VGG_CSV_PATH" --vgg_inference_save_path "$VGG_INFERENCE_SAVE_PATH" --vgg_target_folder "$VGG_TARGET_FOLDER"
Training failed. Please check the logs for more details.

Generating:   5%|‚ñå         | 2/37 [01:47<31:09, 53.42s/it][A
Generating:   8%|‚ñä         | 3/37 [02:39<30:02, 53.03s/it][A
Generating:  11%|‚ñà         | 4/37 [03:32<29:07, 52.97s/it][A
Generating:  14%|‚ñà‚ñé        | 5/37 [04:25<28:10, 52.84s/it][A
Generating:  16%|‚ñà‚ñå        | 6/37 [05:17<27:14, 52.74s/it][A
Generating:  19%|‚ñà‚ñâ        | 7/37 [06:10<26:21, 52.72s/it][A
Generating:  22%|‚ñà‚ñà‚ñè       | 8/37 [07:03<25:29, 52.75s/it][A
Generating:  24%|‚ñà‚ñà‚ñç       | 9/37 [07:55<24:35, 52.70s/it][A
Generating:  27%|‚ñà‚ñà‚ñã       | 10/37 [08:48<23:41, 52.64s/it][A
Generating:  30%|‚ñà‚ñà‚ñâ       | 11/37 [09:40<22:48, 52.63s/it][A
Generating:  32%|‚ñà‚ñà‚ñà‚ñè      | 12/37 [10:33<21:55, 52.61s/it][A
Generating:  35%|‚ñà‚ñà‚ñà‚ñå      | 13/37 [11:26<21:02, 52.59s/it][A
Generating:  38%|‚ñà‚ñà‚ñà‚ñä      | 14/37 [12:18<20:09, 52.59s/it][A
Generating:  41%|‚ñà‚ñà‚ñà‚ñà      | 15/37 [13:11<19:17, 52.62s/it][A/opt/conda/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/opt/conda/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/opt/conda/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/opt/conda/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
ame #28: _PyObject_FastCallDictTstate + 0x187 (0x5622a9b3f4b7 in /opt/conda/bin/python3.10)
[rank3]: frame #29: <unknown function> + 0x145009 (0x5622a9b50009 in /opt/conda/bin/python3.10)
[rank3]: frame #30: <unknown function> + 0x13527b (0x5622a9b4027b in /opt/conda/bin/python3.10)
[rank3]: frame #31: PyObject_Call + 0x20f (0x5622a9b52fcf in /opt/conda/bin/python3.10)
[rank3]: frame #32: _PyEval_EvalFrameDefault + 0x2d62 (0x5622a9b39ce2 in /opt/conda/bin/python3.10)
[rank3]: frame #33: <unknown function> + 0x1474e2 (0x5622a9b524e2 in /opt/conda/bin/python3.10)
[rank3]: frame #34: _PyEval_EvalFrameDefault + 0x133e (0x5622a9b382be in /opt/conda/bin/python3.10)
[rank3]: frame #35: <unknown function> + 0x1474e2 (0x5622a9b524e2 in /opt/conda/bin/python3.10)
[rank3]: frame #36: _PyEval_EvalFrameDefault + 0x133e (0x5622a9b382be in /opt/conda/bin/python3.10)
[rank3]: frame #37: <unknown function> + 0x14e8e7 (0x5622a9b598e7 in /opt/conda/bin/python3.10)
[rank3]: frame #38: PySequence_Tuple + 0x1fc (0x5622a9b26f8c in /opt/conda/bin/python3.10)
[rank3]: frame #39: _PyEval_EvalFrameDefault + 0x30c (0x5622a9b3728c in /opt/conda/bin/python3.10)
[rank3]: frame #40: _PyFunction_Vectorcall + 0x6c (0x5622a9b470cc in /opt/conda/bin/python3.10)
[rank3]: frame #41: _PyEval_EvalFrameDefault + 0x700 (0x5622a9b37680 in /opt/conda/bin/python3.10)
[rank3]: frame #42: _PyFunction_Vectorcall + 0x6c (0x5622a9b470cc in /opt/conda/bin/python3.10)
[rank3]: frame #43: _PyEval_EvalFrameDefault + 0x30c (0x5622a9b3728c in /opt/conda/bin/python3.10)
[rank3]: frame #44: <unknown function> + 0x1cc80c (0x5622a9bd780c in /opt/conda/bin/python3.10)
[rank3]: frame #45: PyEval_EvalCode + 0x87 (0x5622a9bd7757 in /opt/conda/bin/python3.10)
[rank3]: frame #46: <unknown function> + 0x1fcb1a (0x5622a9c07b1a in /opt/conda/bin/python3.10)
[rank3]: frame #47: <unknown function> + 0x1f7fa3 (0x5622a9c02fa3 in /opt/conda/bin/python3.10)
[rank3]: frame #48: <unknown function> + 0x972c2 (0x5622a9aa22c2 in /opt/conda/bin/python3.10)
[rank3]: frame #49: _PyRun_SimpleFileObject + 0x1bd (0x5622a9bfd7dd in /opt/conda/bin/python3.10)
[rank3]: frame #50: _PyRun_AnyFileObject + 0x44 (0x5622a9bfd374 in /opt/conda/bin/python3.10)
[rank3]: frame #51: Py_RunMain + 0x31b (0x5622a9bfa6db in /opt/conda/bin/python3.10)
[rank3]: frame #52: Py_BytesMain + 0x37 (0x5622a9bcae97 in /opt/conda/bin/python3.10)
[rank3]: frame #53: __libc_start_main + 0xea (0x7fdea826dd7a in /lib/x86_64-linux-gnu/libc.so.6)
[rank3]: frame #54: <unknown function> + 0x1bfdae (0x5622a9bcadae in /opt/conda/bin/python3.10)
[rank3]: . This may indicate a possible application crash on rank 0 or a network set up issue.
Ï†ÑÏ≤¥ ÌååÎùºÎØ∏ÌÑ∞ Í∞úÏàò: 1466450500
ÌïôÏäµ Í∞ÄÎä•Ìïú ÌååÎùºÎØ∏ÌÑ∞ Í∞úÏàò: 53166080
[rank2]: Traceback (most recent call last):
[rank2]:   File "/home/jupyter/MMG_01/video_lora_training/train.py", line 426, in <module>
[rank2]:     main(args)
[rank2]:   File "/home/jupyter/MMG_01/video_lora_training/train.py", line 186, in main
[rank2]:     video_unet, optimizer, train_loader = accelerator.prepare(
[rank2]:   File "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py", line 1339, in prepare
[rank2]:     result = tuple(
[rank2]:   File "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py", line 1340, in <genexpr>
[rank2]:     self._prepare_one(obj, first_pass=True, device_placement=d) for obj, d in zip(args, device_placement)
[rank2]:   File "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py", line 1215, in _prepare_one
[rank2]:     return self.prepare_model(obj, device_placement=device_placement)
[rank2]:   File "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py", line 1469, in prepare_model
[rank2]:     model = torch.nn.parallel.DistributedDataParallel(
[rank2]:   File "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 825, in __init__
[rank2]:     _verify_param_shape_across_processes(self.process_group, parameters)
[rank2]:   File "/opt/conda/lib/python3.10/site-packages/torch/distributed/utils.py", line 288, in _verify_param_shape_across_processes
[rank2]:     return dist._verify_params_across_processes(process_group, tensors, logger)
[rank2]: torch.distributed.DistBackendError: [2] is setting up NCCL communicator and retrieving ncclUniqueId from [0] via c10d key-value store by key '0', but store->get('0') got error: failed to recv, got 0 bytes
[rank2]: Exception raised from recvBytes at ../torch/csrc/distributed/c10d/Utils.hpp:670 (most recent call first):
[rank2]: frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7fdec875d446 in /opt/conda/lib/python3.10/site-packages/torch/lib/libc10.so)
[rank2]: frame #1: <unknown function> + 0x5fed998 (0x7fdf03e2f998 in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank2]: frame #2: c10d::TCPStore::doWait(c10::ArrayRef<std::string>, std::chrono::duration<long, std::ratio<1l, 1000l> >) + 0x35b (0x7fdf03e2c64b in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank2]: frame #3: c10d::TCPStore::doGet(std::string const&) + 0x2a (0x7fdf03e2c9ca in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank2]: frame #4: c10d::TCPStore::get(std::string const&) + 0x7a (0x7fdf03e2d83a in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank2]: frame #5: c10d::PrefixStore::get(std::string const&) + 0x31 (0x7fdf03dddbc1 in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank2]: frame #6: c10d::PrefixStore::get(std::string const&) + 0x31 (0x7fdf03dddbc1 in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank2]: frame #7: c10d::PrefixStore::get(std::string const&) + 0x31 (0x7fdf03dddbc1 in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank2]: frame #8: c10d::PrefixStore::get(std::string const&) + 0x31 (0x7fdf03dddbc1 in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank2]: frame #9: c10d::ProcessGroupNCCL::broadcastUniqueNCCLID(ncclUniqueId*, bool, std::string const&, int) + 0xaf (0x7fdec9aa3ebf in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
[rank2]: frame #10: c10d::ProcessGroupNCCL::getNCCLComm(std::string const&, c10::Device&, c10d::OpType, int, bool) + 0xfbd (0x7fdec9aafe5d in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
[rank2]: frame #11: c10d::ProcessGroupNCCL::allgather(std::vector<std::vector<at::Tensor, std::allocator<at::Tensor> >, std::allocator<std::vector<at::Tensor, std::allocator<at::Tensor> > > >&, std::vector<at::Tensor, std::allocator<at::Tensor> >&, c10d::AllgatherOptions const&) + 0x992 (0x7fdec9ac1102 in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
[rank2]: frame #12: <unknown function> + 0x5f902ed (0x7fdf03dd22ed in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank2]: frame #13: <unknown function> + 0x5f994c7 (0x7fdf03ddb4c7 in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank2]: frame #14: <unknown function> + 0x55b224b (0x7fdf033f424b in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank2]: frame #15: <unknown function> + 0x55afad9 (0x7fdf033f1ad9 in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank2]: frame #16: <unknown function> + 0x1a8c3f8 (0x7fdeff8ce3f8 in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank2]: frame #17: <unknown function> + 0x5fa16a3 (0x7fdf03de36a3 in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank2]: frame #18: <unknown function> + 0x5faca2f (0x7fdf03deea2f in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank2]: frame #19: c10d::verify_params_across_processes(c10::intrusive_ptr<c10d::ProcessGroup, c10::detail::intrusive_target_default_null_type<c10d::ProcessGroup> > const&, std::vector<at::Tensor, std::allocator<at::Tensor> > const&, std::optional<std::weak_ptr<c10d::Logger> > const&) + 0x26d (0x7fdf03e5868d in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
[rank2]: frame #20: <unknown function> + 0xd98cb1 (0x7fdf1383fcb1 in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
[rank2]: frame #21: <unknown function> + 0x4cb474 (0x7fdf12f72474 in /opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
[rank2]: frame #22: <unknown function> + 0x13bc46 (0x55a985a16c46 in /opt/conda/bin/python3.10)
[rank2]: frame #23: _PyObject_MakeTpCall + 0x2d3 (0x55a985a0ff73 in /opt/conda/bin/python3.10)
[rank2]: frame #24: _PyEval_EvalFrameDefault + 0x51f6 (0x55a985a0c176 in /opt/conda/bin/python3.10)
[rank2]: frame #25: _PyFunction_Vectorcall + 0x6c (0x55a985a170cc in /opt/conda/bin/python3.10)
[rank2]: frame #26: _PyEval_EvalFrameDefault + 0x30c (0x55a985a0728c in /opt/conda/bin/python3.10)
[rank2]: frame #27: _PyFunction_Vectorcall + 0x6c (0x55a985a170cc in /opt/conda/bin/python3.10)
[rank2]: frame #28: _PyObject_FastCallDictTstate + 0x187 (0x55a985a0f4b7 in /opt/conda/bin/python3.10)
[rank2]: frame #29: <unknown function> + 0x145009 (0x55a985a20009 in /opt/conda/bin/python3.10)
[rank2]: frame #30: <unknown function> + 0x13527b (0x55a985a1027b in /opt/conda/bin/python3.10)
[rank2]: frame #31: PyObject_Call + 0x20f (0x55a985a22fcf in /opt/conda/bin/python3.10)
[rank2]: frame #32: _PyEval_EvalFrameDefault + 0x2d62 (0x55a985a09ce2 in /opt/conda/bin/python3.10)
[rank2]: frame #33: <unknown function> + 0x1474e2 (0x55a985a224e2 in /opt/conda/bin/python3.10)
[rank2]: frame #34: _PyEval_EvalFrameDefault + 0x133e (0x55a985a082be in /opt/conda/bin/python3.10)
[rank2]: frame #35: <unknown function> + 0x1474e2 (0x55a985a224e2 in /opt/conda/bin/python3.10)
[rank2]: frame #36: _PyEval_EvalFrameDefault + 0x133e (0x55a985a082be in /opt/conda/bin/python3.10)
[rank2]: frame #37: <unknown function> + 0x14e8e7 (0x55a985a298e7 in /opt/conda/bin/python3.10)
[rank2]: frame #38: PySequence_Tuple + 0x1fc (0x55a9859f6f8c in /opt/conda/bin/python3.10)
[rank2]: frame #39: _PyEval_EvalFrameDefault + 0x30c (0x55a985a0728c in /opt/conda/bin/python3.10)
[rank2]: frame #40: _PyFunction_Vectorcall + 0x6c (0x55a985a170cc in /opt/conda/bin/python3.10)
[rank2]: frame #41: _PyEval_EvalFrameDefault + 0x700 (0x55a985a07680 in /opt/conda/bin/python3.10)
[rank2]: frame #42: _PyFunction_Vectorcall + 0x6c (0x55a985a170cc in /opt/conda/bin/python3.10)
[rank2]: frame #43: _PyEval_EvalFrameDefault + 0x30c (0x55a985a0728c in /opt/conda/bin/python3.10)
[rank2]: frame #44: <unknown function> + 0x1cc80c (0x55a985aa780c in /opt/conda/bin/python3.10)
[rank2]: frame #45: PyEval_EvalCode + 0x87 (0x55a985aa7757 in /opt/conda/bin/python3.10)
[rank2]: frame #46: <unknown function> + 0x1fcb1a (0x55a985ad7b1a in /opt/conda/bin/python3.10)
[rank2]: frame #47: <unknown function> + 0x1f7fa3 (0x55a985ad2fa3 in /opt/conda/bin/python3.10)
[rank2]: frame #48: <unknown function> + 0x972c2 (0x55a9859722c2 in /opt/conda/bin/python3.10)
[rank2]: frame #49: _PyRun_SimpleFileObject + 0x1bd (0x55a985acd7dd in /opt/conda/bin/python3.10)
[rank2]: frame #50: _PyRun_AnyFileObject + 0x44 (0x55a985acd374 in /opt/conda/bin/python3.10)
[rank2]: frame #51: Py_RunMain + 0x31b (0x55a985aca6db in /opt/conda/bin/python3.10)
[rank2]: frame #52: Py_BytesMain + 0x37 (0x55a985a9ae97 in /opt/conda/bin/python3.10)
[rank2]: frame #53: __libc_start_main + 0xea (0x7fdf14be9d7a in /lib/x86_64-linux-gnu/libc.so.6)
[rank2]: frame #54: <unknown function> + 0x1bfdae (0x55a985a9adae in /opt/conda/bin/python3.10)
[rank2]: . This may indicate a possible application crash on rank 0 or a network set up issue.
git root error: Cmd('git') failed due to: exit code(128)
  cmdline: git rev-parse --show-toplevel
  stderr: 'fatal: detected dubious ownership in repository at '/home/jupyter/MMG_01'
To add an exception for this directory, call:

	git config --global --add safe.directory /home/jupyter/MMG_01'
wandb: Currently logged in as: rtrt505 to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.6
wandb: Run data is saved locally in /home/jupyter/MMG_01/wandb/run-20250211_013631-rqzgiq8b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run video_lora_training
wandb: ‚≠êÔ∏è View project at https://wandb.ai/rtrt505/video_teacher_lora_training_0210
wandb: üöÄ View run at https://wandb.ai/rtrt505/video_teacher_lora_training_0210/runs/rqzgiq8b
AE working on z of shape (1, 4, 64, 64) = 16384 dimensions.
WARNING:py.warnings:/opt/conda/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)

INFO:root:Loaded ViT-H-14 model config.
AE working on z of shape (1, 4, 64, 64) = 16384 dimensions.
WARNING:py.warnings:/opt/conda/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)

INFO:root:Loaded ViT-H-14 model config.
WARNING:py.warnings:/home/jupyter/MMG_01/video_lora_training/train.py:156: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(args.videocrafter_ckpt)['state_dict']

WARNING:py.warnings:/home/jupyter/MMG_01/video_lora_training/train.py:156: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(args.videocrafter_ckpt)['state_dict']

Ï†ÑÏ≤¥ ÌååÎùºÎØ∏ÌÑ∞ Í∞úÏàò: 1466450500
ÌïôÏäµ Í∞ÄÎä•Ìïú ÌååÎùºÎØ∏ÌÑ∞ Í∞úÏàò: 53166080
Ï†ÑÏ≤¥ ÌååÎùºÎØ∏ÌÑ∞ Í∞úÏàò: 1466450500
ÌïôÏäµ Í∞ÄÎä•Ìïú ÌååÎùºÎØ∏ÌÑ∞ Í∞úÏàò: 53166080
